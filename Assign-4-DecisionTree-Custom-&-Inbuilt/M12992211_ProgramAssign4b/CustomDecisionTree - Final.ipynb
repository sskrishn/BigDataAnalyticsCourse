{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To find spark in this instance and Creating spark context and session and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "#sc.stop()\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Binned train data to train the model using Decision Tree which is implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = sc.textFile(\"COPY_binned_train_200.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Reduce 1 which takes entire data as input and generate (\"class label\", count) as key value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 241), ('1', 153)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapRed1op = text_file.flatMap(lambda line: line.split(\"\\n\")) \\\n",
    "             .map(lambda y: (y[0], 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "mapRed1op.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Entropy calculation by collecting rdd and changing to dictionary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting mapReduce 1 output to dictionarty:{'0': 241, '1': 153}\n",
      "Total Entropy:0.9637100175188218\n"
     ]
    }
   ],
   "source": [
    "map1op=mapRed1op.collect()\n",
    "map1opDic=dict(map1op)\n",
    "print(\"Converting mapReduce 1 output to dictionarty:\"+str(map1opDic))\n",
    "import math\n",
    "n0=map1opDic.get('0')\n",
    "n1=map1opDic.get('1')\n",
    "n=n0+n1\n",
    "totEntr=-(((n1/n)*(math.log(n1/n,2)))+((n0/n)*(math.log(n0/n,2))))\n",
    "print(\"Total Entropy:\"+str(totEntr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_tr_data=text_file.flatMap(lambda line: line.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Methods To implement Decision Tree and get the tree form \n",
    "\n",
    "### Func: 'get_branching_with_bestAttr' \n",
    "#### Inputs: Data(in rdd form) and Total entropy for Data\n",
    "#### Ouput: Dictionary with best Attribute to split as 'index' and splits of data based on index as 'groups'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branching_with_bestAttr(dataset,totEntr):\n",
    "    index_val=get_bestAttr(dataset,totEntr)\n",
    "    print(\"Best Attribute is \"+str(index_val))\n",
    "    groups=get_branches(index_val,dataset)\n",
    "    display(groups)\n",
    "    return {'index':index_val, 'groups':groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: 'get_branches' \n",
    "#### Inputs: index (column number) based on which split should be done and Data(in rdd form)\n",
    "#### Ouput: Two subsets of data as left and right ( left is with rows[index]= '0.0' and right is with rows[index]='1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branches(index, dataset):\n",
    "    left =dataset.filter(lambda y: y.split(\",\")[index+1]=='0.0')\n",
    "    right=dataset.filter(lambda y: y.split(\",\")[index+1]=='1.0')\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Reduce2 (Phase 2) to calculate key value pairs which will be used to calculate best attribute \n",
    "#### Here final (key,value) pairs will be ('col_colNumber_colValue_classLabel', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: 'get_bestAttr' \n",
    "#### Inputs: index (column number) based on which split should be done and Data(in rdd form)\n",
    "#### Ouput: Two subsets of data as left and right ( left is with rows[index]= '0.0' and right is with rows[index]='1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bestAttr(dataset,totEntr):\n",
    "    a=dataset \\\n",
    "    .map(lambda  y:[(\"col_\"+str(i+2)+\"_\"+str(v)+\"_\"+str(u),1) for i,(v,u) in enumerate(zip(y.split(\",\")[1:],itertools.repeat(y.split(\",\")[0])))]) \\\n",
    "    .flatMap(lambda z:z) \\\n",
    "    .reduceByKey(lambda x,y:(x+y))\n",
    "    tm2op=a.collect()\n",
    "    print(\"Printing first five key-value pairs after MapReduce2\")\n",
    "    print(tm2op[:5])\n",
    "    tm2opDic=dict(tm2op)\n",
    "    ind=get_Index(tm2opDic,totEntr)\n",
    "    return ind  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: 'get_Index' \n",
    "#### Inputs: MapReduce2 Output as dictionary and Total Entropy for that data\n",
    "#### Ouput: Best Attribute based on the entropy and weighted entropy and Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Index(map2opDic,totEntr):\n",
    "    gainlist=[]\n",
    "    for i in range(2,17):\n",
    "        tmplist1=[]\n",
    "        tmplist2=[]\n",
    "        for j in range(0,2):\n",
    "            a0=map2opDic.get(\"col_\"+str(i)+\"_\"+str(j)+\".0\"+\"_0.0\",0)\n",
    "            a1=map2opDic.get(\"col_\"+str(i)+\"_\"+str(j)+\".0\"+\"_1.0\",0)\n",
    "            a=a1+a0\n",
    "            tmpEntr=0\n",
    "            if a0==0 and a1!=0:\n",
    "                tmpEntr=tmpEntr+(-(((a1/a)*(math.log(a1/a,2)))))\n",
    "            elif a1==0 and a0!=0:\n",
    "                tmpEntr=tmpEntr+(-(((a0/a)*(math.log(a0/a,2)))))\n",
    "            elif a1!=0 and a0!=0:\n",
    "                tmpEntr=tmpEntr+(-(((a1/a)*(math.log(a1/a,2)))+((a0/a)*(math.log(a0/a,2)))))\n",
    "            else:\n",
    "                tmpEntr=0\n",
    "            tmplist1.append(tmpEntr)\n",
    "            tmplist2.append(a)\n",
    "        sumEnt=0\n",
    "        totalRec=0\n",
    "        for k in range(len(tmplist1)):\n",
    "            sumEnt=sumEnt+(tmplist1[k]*tmplist2[k])\n",
    "            totalRec=totalRec+tmplist2[k]\n",
    "        gainlist.append((totEntr-float(sumEnt/totalRec)))\n",
    "    return gainlist.index(max(gainlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: 'split' - split the main node recursively until given depth\n",
    "#### Inputs: Main Node (Dictionary with left and right keys), max_depth (depth at which decision tree should stop),min_size( no of records in particular split at which no futhur split continue on that branch), Total entropy\n",
    "#### Ouput:  Final Tree with best attribute values at each level and groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: 'terminate' - function to calculate the class label at end of each decision tree for that branch based on majority of classes in that particular group\n",
    "#### Inputs: Group (Dictionary with left and right subsets of data)\n",
    "#### Ouput: Class label based on majority (Here Map Reduce is used to calculate count of class labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# Create a terminal node value\n",
    "def terminate(group):\n",
    "    #outcomes = [row[0] for row in group]\n",
    "    tmp = group \\\n",
    "             .map(lambda y: (y[0], 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "    x=tmp.collect()\n",
    "    #return x;\n",
    "    if len(x)!=0:\n",
    "        return max(x,key=itemgetter(1))[0]\n",
    "    else:\n",
    "        return 'NULL'\n",
    " \n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth,totEntr):\n",
    "    left, right = node['groups']\n",
    "    #left= left.cache()\n",
    "    #right=right.cache()\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = terminate(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = terminate(left), terminate(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left.collect()) <= min_size:\n",
    "        node['left'] = terminate(left)\n",
    "    else:\n",
    "        node['left'] = get_branching_with_bestAttr(left,totEntr)\n",
    "        split(node['left'], max_depth, min_size, depth+1,totEntr)\n",
    "    # process right child\n",
    "    if len(right.collect()) <= min_size:\n",
    "        node['right'] = terminate(right)\n",
    "    else:\n",
    "        node['right'] = get_branching_with_bestAttr(right,totEntr)\n",
    "        split(node['right'], max_depth, min_size, depth+1,totEntr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Root Node  (first best attribute and first split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first five key-value pairs after MapReduce2\n",
      "[('col_2_0.0_0.0', 166), ('col_3_0.0_0.0', 183), ('col_4_1.0_0.0', 95), ('col_5_0.0_0.0', 186), ('col_6_0.0_0.0', 147)]\n",
      "Best Attribute is 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PythonRDD[13] at RDD at PythonRDD.scala:52,\n",
       " PythonRDD[14] at RDD at PythonRDD.scala:52)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root=get_branching_with_bestAttr(all_tr_data,totEntr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From root node splitting and getting decision tree upto depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first five key-value pairs after MapReduce2\n",
      "[('col_2_0.0_0.0', 130), ('col_3_0.0_0.0', 147), ('col_4_1.0_0.0', 66), ('col_5_0.0_0.0', 186), ('col_6_0.0_0.0', 122)]\n",
      "Best Attribute is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PythonRDD[20] at RDD at PythonRDD.scala:52,\n",
       " PythonRDD[21] at RDD at PythonRDD.scala:52)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first five key-value pairs after MapReduce2\n",
      "[('col_2_0.0_0.0', 130), ('col_3_0.0_0.0', 104), ('col_4_1.0_0.0', 51), ('col_5_0.0_0.0', 130), ('col_6_0.0_0.0', 87)]\n",
      "Best Attribute is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PythonRDD[27] at RDD at PythonRDD.scala:52,\n",
       " PythonRDD[28] at RDD at PythonRDD.scala:52)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first five key-value pairs after MapReduce2\n",
      "[('col_2_1.0_0.0', 56), ('col_3_0.0_0.0', 43), ('col_4_0.0_0.0', 41), ('col_5_0.0_0.0', 56), ('col_6_1.0_0.0', 21)]\n",
      "Best Attribute is 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PythonRDD[44] at RDD at PythonRDD.scala:52,\n",
       " PythonRDD[45] at RDD at PythonRDD.scala:52)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first five key-value pairs after MapReduce2\n",
      "[('col_2_0.0_0.0', 36), ('col_3_0.0_0.0', 36), ('col_4_1.0_0.0', 29), ('col_5_1.0_0.0', 55), ('col_6_1.0_0.0', 30)]\n",
      "Best Attribute is 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PythonRDD[61] at RDD at PythonRDD.scala:52,\n",
       " PythonRDD[62] at RDD at PythonRDD.scala:52)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first five key-value pairs after MapReduce2\n",
      "[('col_2_0.0_0.0', 24), ('col_3_0.0_0.0', 36), ('col_4_1.0_0.0', 19), ('col_5_1.0_0.0', 36), ('col_6_1.0_0.0', 20)]\n",
      "Best Attribute is 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PythonRDD[68] at RDD at PythonRDD.scala:52,\n",
       " PythonRDD[69] at RDD at PythonRDD.scala:52)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first five key-value pairs after MapReduce2\n",
      "[('col_2_0.0_0.0', 12), ('col_3_1.0_0.0', 19), ('col_4_1.0_0.0', 10), ('col_5_1.0_0.0', 19), ('col_6_0.0_0.0', 9)]\n",
      "Best Attribute is 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PythonRDD[85] at RDD at PythonRDD.scala:52,\n",
       " PythonRDD[86] at RDD at PythonRDD.scala:52)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split(root, 3, 5, 1,totEntr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Decision tree calculated based on implementation using two map reduce programs in a loop at different places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here left is such that index ==0 and right is such that index ==1 and index is best attribute at that level in decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 3,\n",
       " 'left': {'index': 0,\n",
       "  'left': {'index': 0, 'left': '0', 'right': 'NULL'},\n",
       "  'right': {'index': 1, 'left': '0', 'right': '0'}},\n",
       " 'right': {'index': 1,\n",
       "  'left': {'index': 12, 'left': '0', 'right': '0'},\n",
       "  'right': {'index': 7, 'left': '0', 'right': '1'}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Binned test data to calculate performance metrics of  the model using Decision Tree which is implemented## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = sc.textFile(\"COPY_binned_test_200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data=test_file.flatMap(lambda line: line.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list=all_test_data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_df=[]\n",
    "for rw in test_list:\n",
    "    test_list_df.append(rw.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: 'predict' - function to calculate predictions for records in test data \n",
    "#### Inputs: Decision Tree and particular row (record)\n",
    "#### Ouput: Class label based on tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "    if row[node['index']+1] == '0.0':\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over test data and caclulating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "org=[]\n",
    "for row in test_list_df:\n",
    "    pre=predict(root,row)\n",
    "    predictions.append(pre)\n",
    "    org.append(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Methods to calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conf_matrix(expected, predicted, n_classes):\n",
    "    m = [[0] * n_classes for i in range(n_classes)]\n",
    "    for pred, exp in zip(predicted, expected):\n",
    "        if exp=='0.0':\n",
    "            exp=0\n",
    "        else:\n",
    "            exp=1\n",
    "        m[int(exp)][int(pred)] += 1\n",
    "    return m\n",
    "\n",
    "def recall_1(con_mat):\n",
    "    if (con_mat[1][1] + con_mat[1][0])==0:\n",
    "        return float('NaN')\n",
    "    val=con_mat[1][1] / (con_mat[1][1] + con_mat[1][0] )\n",
    "    return val\n",
    "def recall_0(con_mat):\n",
    "    if (con_mat[0][0] + con_mat[0][1])==0:\n",
    "        return float('NaN')\n",
    "    val=con_mat[0][0] / (con_mat[0][1] + con_mat[0][0] )\n",
    "    return val\n",
    "def prec_1(con_mat):\n",
    "    if (con_mat[1][1] + con_mat[0][1])==0:\n",
    "        return float('NaN')\n",
    "    val=con_mat[1][1] / (con_mat[1][1] + con_mat[0][1] )\n",
    "    return val\n",
    "def prec_0(con_mat):\n",
    "    if (con_mat[0][0] + con_mat[1][0])==0:\n",
    "        return float('NaN')\n",
    "    val=con_mat[0][0] / (con_mat[1][0] + con_mat[0][0] )\n",
    "    return val\n",
    "def accuracy(con_mat):\n",
    "    val=(con_mat[0][0] +con_mat[1][1])/ (con_mat[0][0] + con_mat[1][0] +con_mat[0][1]+con_mat[1][1])\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics calculated for Decision Tree Implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of label-1 (M)  0.94\n",
      "Precision of label-0 (B) 0.904\n",
      "Recall of label-1 (M)     0.7966101694915254\n",
      "Recall of label-0 (B)    0.9741379310344828\n",
      "Accuracy         0.9142857142857143\n",
      "Confusion Matrix\n",
      " [[113, 3], [12, 47]]\n"
     ]
    }
   ],
   "source": [
    "conMat=create_conf_matrix(org,predictions,2)\n",
    "recall_1(conMat)\n",
    "recall_0(conMat)\n",
    "prec_1(conMat)\n",
    "prec_0(conMat)\n",
    "print('Precision of label-1 (M) ', prec_1(conMat))\n",
    "print('Precision of label-0 (B)', prec_0(conMat))\n",
    "print( 'Recall of label-1 (M)    ', recall_1(conMat))\n",
    "print( 'Recall of label-0 (B)   ', recall_0(conMat))\n",
    "#print ('F-1 Score         ', metrics.fMeasure())\n",
    "print ('Accuracy        ', accuracy(conMat))\n",
    "print ('Confusion Matrix\\n', conMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Structure for Decision Tree Implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 3,\n",
       " 'left': {'index': 0,\n",
       "  'left': {'index': 0, 'left': '0', 'right': 'NULL'},\n",
       "  'right': {'index': 1, 'left': '0', 'right': '0'}},\n",
       " 'right': {'index': 1,\n",
       "  'left': {'index': 12, 'left': '0', 'right': '0'},\n",
       "  'right': {'index': 7, 'left': '0', 'right': '1'}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Compare results on implemented Decision Tree with MLlib Decision Tree results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files which are having same set of train and test records but not binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)\n",
    "training_data_1 = spark.read.csv('COPY_nobin_train_org_200.csv', header = False, inferSchema = True)\n",
    "testing_data_1=spark.read.csv('COPY_nobin_test_org_200.csv', header = False, inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier using MLlib with maxDepth=3 and impurity =entropy and maxBins=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel classifier of depth 3 with 13 nodes\n",
      "  If (feature 3 <= 0.06445999999999999)\n",
      "   If (feature 0 <= 19.075)\n",
      "    Predict: 0.0\n",
      "   Else (feature 0 > 19.075)\n",
      "    If (feature 1 <= 561.15)\n",
      "     Predict: 0.0\n",
      "    Else (feature 1 > 561.15)\n",
      "     Predict: 0.0\n",
      "  Else (feature 3 > 0.06445999999999999)\n",
      "   If (feature 1 <= 561.15)\n",
      "    If (feature 12 <= 0.1313)\n",
      "     Predict: 0.0\n",
      "    Else (feature 12 > 0.1313)\n",
      "     Predict: 0.0\n",
      "   Else (feature 1 > 561.15)\n",
      "    If (feature 7 <= 25.91)\n",
      "     Predict: 0.0\n",
      "    Else (feature 7 > 25.91)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "\n",
    "def labelData(data):\n",
    "    # label: row[end], features: row[0:end-1]\n",
    "    return data.rdd.map(lambda row: LabeledPoint(row[0], row[1:]))\n",
    "\n",
    "training_data = labelData(training_data_1)\n",
    "testing_data=labelData(testing_data_1)\n",
    "\n",
    "model = DecisionTree.trainClassifier(training_data, numClasses=2, maxDepth=3,\n",
    "                                     categoricalFeaturesInfo={},\n",
    "                                     impurity='entropy', maxBins=2)\n",
    "print(model.toDebugString())\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics calculated for MLlib's Decision Tree of our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of label-1 (M)  0.94\n",
      "Precision of label-0 (B) 0.904\n",
      "Recall of label-1 (M)     0.7966101694915254\n",
      "Recall of label-0 (B)    0.9741379310344828\n",
      "F-1 Score          0.9142857142857143\n",
      "Accuracy         0.9142857142857143\n",
      "Confusion Matrix\n",
      " [[113.   3.]\n",
      " [ 12.  47.]]\n"
     ]
    }
   ],
   "source": [
    "def getPredictionsLabels(model, test_data):\n",
    "    predictions = model.predict(test_data.map(lambda r: r.features))\n",
    "    return predictions.zip(test_data.map(lambda r: r.label))\n",
    "\n",
    "def printMetrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print('Precision of label-1 (M) ', metrics.precision(1))\n",
    "    print('Precision of label-0 (B)', metrics.precision(0))\n",
    "    print( 'Recall of label-1 (M)    ', metrics.recall(1))\n",
    "    print( 'Recall of label-0 (B)   ', metrics.recall(0))\n",
    "    print ('F-1 Score         ', metrics.fMeasure())\n",
    "    print ('Accuracy        ', metrics.accuracy)\n",
    "    print ('Confusion Matrix\\n', metrics.confusionMatrix().toArray())\n",
    "\n",
    "predictions_and_labels = getPredictionsLabels(model, testing_data)\n",
    "printMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. The choice of parameters and attribute selection metric (Gini index, info gain, etc.) used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using same parameters which I have used in problem 1, but here I have chosen no of bins=2. Since the library I have used is based on CART algorithm and always node at any level will have two child nodes (this internal best splits will be decided based on entropy and it will take every value in record as range for bin and caclulates best splits which takes more time). If no of bins=2 then CART algorithm is similar to ID3 algorithm which is easy to process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Any Assumptions Made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same assumptions which are made in problem 1 are assumed here as follows :\n",
    "\n",
    "1) Removed 'id' column assuming it does not effect 'diagnosis' label\n",
    "\n",
    "2) Here highly correlated features are dropped by considering only one feature from highly correlated features assuming those feature won't effect the 'diagonsis' the column. (radius_mean, perimeter_mean, area_mean are correlated with each other so I am considering only area_mean. Apart from these, radius_se, perimeter_se and area_se are correlated and I only used area_se. radius_worst, perimeter_worst and area_worst are correlated so I used area_worst. Also compactness_mean, concavity_mean and concave points_mean are correlated with each other.Therefore I only choose concavity_mean. compactness_worst, concavity_worst and concave points_worst so I used concavity_worst. Compactness_se, concavity_se and concave points_se so I used concavity_se. texture_mean and texture_worst are correlated and I used texture_mean. area_worst and area_mean are correlated, I used area_mean. concavity_worst and concavity_mean are correlated, I used concavity_mean)\n",
    "\n",
    "3) Tried with different seeds and data has been splitted 70:30 and randomly took seed 200 for no of bins =2 for which decent accuracy has been obtained (91.4%)\n",
    "\n",
    "4) As mentioned above no of bins =2 has been considered and compared the both api and implemented decision tree preassuming both results will be same\n",
    "\n",
    "5) CART implementation works same as ID3 when no of bins =2\n",
    "\n",
    "6) Cross Validation has not been done while doing decision tree implementation as main purpose is to compare the results with that of Api. I got same results for both decision tree. (Also I have run with different seeds which is nothing but for different combination of training data and observed for seed =200 is giving good results which can be considered as validation test.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Decision tree Obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 3,\n",
       " 'left': {'index': 0,\n",
       "  'left': {'index': 0, 'left': '0', 'right': 'NULL'},\n",
       "  'right': {'index': 1, 'left': '0', 'right': '0'}},\n",
       " 'right': {'index': 1,\n",
       "  'left': {'index': 12, 'left': '0', 'right': '0'},\n",
       "  'right': {'index': 7, 'left': '0', 'right': '1'}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "1)Here condition for left is value=='0.0' and condition for right is value=='1.0'\n",
    "\n",
    "2)Here Null indicates that side no branching (pruned). To have uniform length/nodes at every level considering dummy brnach and finally assigning null value (Though while predicting it will never travers through that branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Performance shown by the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of label-1 (M)  0.94\n",
      "Precision of label-0 (B) 0.904\n",
      "Recall of label-1 (M)     0.7966101694915254\n",
      "Recall of label-0 (B)    0.9741379310344828\n",
      "Accuracy         0.9142857142857143\n",
      "Confusion Matrix\n",
      " [[113, 3], [12, 47]]\n"
     ]
    }
   ],
   "source": [
    "conMat=create_conf_matrix(org,predictions,2)\n",
    "recall_1(conMat)\n",
    "recall_0(conMat)\n",
    "prec_1(conMat)\n",
    "prec_0(conMat)\n",
    "print('Precision of label-1 (M) ', prec_1(conMat))\n",
    "print('Precision of label-0 (B)', prec_0(conMat))\n",
    "print( 'Recall of label-1 (M)    ', recall_1(conMat))\n",
    "print( 'Recall of label-0 (B)   ', recall_0(conMat))\n",
    "#print ('F-1 Score         ', metrics.fMeasure())\n",
    "print ('Accuracy        ', accuracy(conMat))\n",
    "print ('Confusion Matrix\\n', conMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Results Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got same tree and same performance metrics for both decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "\n",
    "2)  https://spark.apache.org/docs/2.2.0/mllib-decision-tree.html\n",
    "\n",
    "3)  https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html\n",
    "\n",
    "4)  https://mapr.com/blog/churn-prediction-pyspark-using-mllib-and-ml-packages/\n",
    "\n",
    "5)  https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/kernels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
